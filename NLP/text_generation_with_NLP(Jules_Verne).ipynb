{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "text generation with NLP(Jules Verne).ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY-4gwRF-2d-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc6pWjYb_EzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8763a55f-c10f-4f78-fafc-c8eaf3ba96b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuyLIY8Q-2eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = '/content/around the world in eighty days.txt' #https://www.gutenberg.org/ebooks/103"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE46jhqs-2eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = open(data,'r',encoding='utf-8').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y_25wS0-2eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GvjKTtW-2eR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e76c9b65-7b88-4569-ac40-7b7136514e9b"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KguSoEZ-2eX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "16894833-d70a-4204-f4e4-f16c9170ed2f"
      },
      "source": [
        "char_to_ind = {char:i for i,char in enumerate(vocab)}\n",
        "print(char_to_ind)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5, '(': 6, ')': 7, '+': 8, ',': 9, '-': 10, '.': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '?': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'E': 29, 'F': 30, 'G': 31, 'H': 32, 'I': 33, 'J': 34, 'K': 35, 'L': 36, 'M': 37, 'N': 38, 'O': 39, 'P': 40, 'Q': 41, 'R': 42, 'S': 43, 'T': 44, 'U': 45, 'V': 46, 'W': 47, 'X': 48, 'Y': 49, 'Z': 50, '`': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2sNnAso-2ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind_to_char = np.array(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAa4bxZx-2ei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f733656b-d6e9-45bd-9207-5d7b145ad6fb"
      },
      "source": [
        "ind_to_char[56] "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmtCLmP5-2en",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16cbe788-d104-4999-95e5-0153dde02e83"
      },
      "source": [
        "char_to_ind['e']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRzNNr-D-2er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh215PCL-2eu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48fcbefd-65c7-48e2-9e10-95e21e2025c5"
      },
      "source": [
        "print(encoded_text)\n",
        "print(encoded_text.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[27 59 52 ... 63 55 24]\n",
            "(367444,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qXX4xE9-2ez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a7549364-94a9-41e6-8814-5cf07681b3da"
      },
      "source": [
        "sample = text[101:202]\n",
        "print(sample)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAN\n",
            "\n",
            "\n",
            "Mr. Phileas Fogg lived, in 1872, at No. 7, Saville Row, Burlington\n",
            "Gardens, the house in which \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d5PPJE4-2e4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3be7c9c7-19e9-4ea1-dbe6-4a5fa6d6b304"
      },
      "source": [
        "encoded_text[101:202]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([37, 25, 38,  0,  0,  0, 37, 69, 11,  1, 40, 59, 60, 63, 56, 52, 70,\n",
              "        1, 30, 66, 58, 58,  1, 63, 60, 73, 56, 55,  9,  1, 60, 65,  1, 13,\n",
              "       20, 19, 14,  9,  1, 52, 71,  1, 38, 66, 11,  1, 19,  9,  1, 43, 52,\n",
              "       73, 60, 63, 63, 56,  1, 42, 66, 74,  9,  1, 26, 72, 69, 63, 60, 65,\n",
              "       58, 71, 66, 65,  0, 31, 52, 69, 55, 56, 65, 70,  9,  1, 71, 59, 56,\n",
              "        1, 59, 66, 72, 70, 56,  1, 60, 65,  1, 74, 59, 60, 54, 59,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kp1pHIM-2e9",
        "colab_type": "text"
      },
      "source": [
        "# Creating batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrQAjbtV-2e-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "9449f5eb-c083-4158-fca7-c0c072fc6672"
      },
      "source": [
        "print(text[:1000])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chapter I\n",
            "\n",
            "IN WHICH PHILEAS FOGG AND PASSEPARTOUT ACCEPT EACH OTHER,\n",
            "THE ONE AS MASTER, THE OTHER AS MAN\n",
            "\n",
            "\n",
            "Mr. Phileas Fogg lived, in 1872, at No. 7, Saville Row, Burlington\n",
            "Gardens, the house in which Sheridan died in 1814.  He was one of the\n",
            "most noticeable members of the Reform Club, though he seemed always to\n",
            "avoid attracting attention; an enigmatical personage, about whom little\n",
            "was known, except that he was a polished man of the world.  People said\n",
            "that he resembled Byron--at least that his head was Byronic; but he was\n",
            "a bearded, tranquil Byron, who might live on a thousand years without\n",
            "growing old.\n",
            "\n",
            "Certainly an Englishman, it was more doubtful whether Phileas Fogg was\n",
            "a Londoner.  He was never seen on 'Change, nor at the Bank, nor in the\n",
            "counting-rooms of the \"City\"; no ships ever came into London docks of\n",
            "which he was the owner; he had no public employment; he had never been\n",
            "entered at any of the Inns of Court, either at the Temple, or Lincoln's\n",
            "Inn, or Gray's Inn; nor had hi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db7bkmA4-2fB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paragraph = '''\n",
        "Mr. Phileas Fogg lived, in 1872, at No. 7, Saville Row, Burlington\n",
        "Gardens, the house in which Sheridan died in 1814.  He was one of the\n",
        "most noticeable members of the Reform Club, though he seemed always to\n",
        "avoid attracting attention; an enigmatical personage, about whom little\n",
        "was known, except that he was a polished man of the world.  People said\n",
        "that he resembled Byron--at least that his head was Byronic; but he was\n",
        "a bearded, tranquil Byron, who might live on a thousand years without\n",
        "growing old.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwBoMmy3-2fF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "863128b5-fb80-4a05-a1c0-7a496421bb4c"
      },
      "source": [
        "len(paragraph)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "508"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTJMYLSi-2fI",
        "colab_type": "text"
      },
      "source": [
        "# training sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jNpRmz7-2fJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = 250"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soAEvNnK-2fO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_seq = len(text)//(seq_len+1) # indexing starts from 0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olyfL7_G-2fS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c75cd24-728f-4927-e2d5-0adb66ccc2f0"
      },
      "source": [
        "print(f'length of sequences in text {total_seq}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of sequences in text 1463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seMQvw30-2fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IIVg1H--2fY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9046a001-c835-48c2-c3a0-73dc7bc6dcc7"
      },
      "source": [
        "for i in char_dataset.take(500):\n",
        "    print(ind_to_char[i.numpy()])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C\n",
            "h\n",
            "a\n",
            "p\n",
            "t\n",
            "e\n",
            "r\n",
            " \n",
            "I\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "I\n",
            "N\n",
            " \n",
            "W\n",
            "H\n",
            "I\n",
            "C\n",
            "H\n",
            " \n",
            "P\n",
            "H\n",
            "I\n",
            "L\n",
            "E\n",
            "A\n",
            "S\n",
            " \n",
            "F\n",
            "O\n",
            "G\n",
            "G\n",
            " \n",
            "A\n",
            "N\n",
            "D\n",
            " \n",
            "P\n",
            "A\n",
            "S\n",
            "S\n",
            "E\n",
            "P\n",
            "A\n",
            "R\n",
            "T\n",
            "O\n",
            "U\n",
            "T\n",
            " \n",
            "A\n",
            "C\n",
            "C\n",
            "E\n",
            "P\n",
            "T\n",
            " \n",
            "E\n",
            "A\n",
            "C\n",
            "H\n",
            " \n",
            "O\n",
            "T\n",
            "H\n",
            "E\n",
            "R\n",
            ",\n",
            "\n",
            "\n",
            "T\n",
            "H\n",
            "E\n",
            " \n",
            "O\n",
            "N\n",
            "E\n",
            " \n",
            "A\n",
            "S\n",
            " \n",
            "M\n",
            "A\n",
            "S\n",
            "T\n",
            "E\n",
            "R\n",
            ",\n",
            " \n",
            "T\n",
            "H\n",
            "E\n",
            " \n",
            "O\n",
            "T\n",
            "H\n",
            "E\n",
            "R\n",
            " \n",
            "A\n",
            "S\n",
            " \n",
            "M\n",
            "A\n",
            "N\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "M\n",
            "r\n",
            ".\n",
            " \n",
            "P\n",
            "h\n",
            "i\n",
            "l\n",
            "e\n",
            "a\n",
            "s\n",
            " \n",
            "F\n",
            "o\n",
            "g\n",
            "g\n",
            " \n",
            "l\n",
            "i\n",
            "v\n",
            "e\n",
            "d\n",
            ",\n",
            " \n",
            "i\n",
            "n\n",
            " \n",
            "1\n",
            "8\n",
            "7\n",
            "2\n",
            ",\n",
            " \n",
            "a\n",
            "t\n",
            " \n",
            "N\n",
            "o\n",
            ".\n",
            " \n",
            "7\n",
            ",\n",
            " \n",
            "S\n",
            "a\n",
            "v\n",
            "i\n",
            "l\n",
            "l\n",
            "e\n",
            " \n",
            "R\n",
            "o\n",
            "w\n",
            ",\n",
            " \n",
            "B\n",
            "u\n",
            "r\n",
            "l\n",
            "i\n",
            "n\n",
            "g\n",
            "t\n",
            "o\n",
            "n\n",
            "\n",
            "\n",
            "G\n",
            "a\n",
            "r\n",
            "d\n",
            "e\n",
            "n\n",
            "s\n",
            ",\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "h\n",
            "o\n",
            "u\n",
            "s\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            " \n",
            "w\n",
            "h\n",
            "i\n",
            "c\n",
            "h\n",
            " \n",
            "S\n",
            "h\n",
            "e\n",
            "r\n",
            "i\n",
            "d\n",
            "a\n",
            "n\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            "d\n",
            " \n",
            "i\n",
            "n\n",
            " \n",
            "1\n",
            "8\n",
            "1\n",
            "4\n",
            ".\n",
            " \n",
            " \n",
            "H\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "o\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "\n",
            "\n",
            "m\n",
            "o\n",
            "s\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "t\n",
            "i\n",
            "c\n",
            "e\n",
            "a\n",
            "b\n",
            "l\n",
            "e\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "b\n",
            "e\n",
            "r\n",
            "s\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "R\n",
            "e\n",
            "f\n",
            "o\n",
            "r\n",
            "m\n",
            " \n",
            "C\n",
            "l\n",
            "u\n",
            "b\n",
            ",\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            "g\n",
            "h\n",
            " \n",
            "h\n",
            "e\n",
            " \n",
            "s\n",
            "e\n",
            "e\n",
            "m\n",
            "e\n",
            "d\n",
            " \n",
            "a\n",
            "l\n",
            "w\n",
            "a\n",
            "y\n",
            "s\n",
            " \n",
            "t\n",
            "o\n",
            "\n",
            "\n",
            "a\n",
            "v\n",
            "o\n",
            "i\n",
            "d\n",
            " \n",
            "a\n",
            "t\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            "t\n",
            "t\n",
            "e\n",
            "n\n",
            "t\n",
            "i\n",
            "o\n",
            "n\n",
            ";\n",
            " \n",
            "a\n",
            "n\n",
            " \n",
            "e\n",
            "n\n",
            "i\n",
            "g\n",
            "m\n",
            "a\n",
            "t\n",
            "i\n",
            "c\n",
            "a\n",
            "l\n",
            " \n",
            "p\n",
            "e\n",
            "r\n",
            "s\n",
            "o\n",
            "n\n",
            "a\n",
            "g\n",
            "e\n",
            ",\n",
            " \n",
            "a\n",
            "b\n",
            "o\n",
            "u\n",
            "t\n",
            " \n",
            "w\n",
            "h\n",
            "o\n",
            "m\n",
            " \n",
            "l\n",
            "i\n",
            "t\n",
            "t\n",
            "l\n",
            "e\n",
            "\n",
            "\n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "k\n",
            "n\n",
            "o\n",
            "w\n",
            "n\n",
            ",\n",
            " \n",
            "e\n",
            "x\n",
            "c\n",
            "e\n",
            "p\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "a\n",
            "s\n",
            " \n",
            "a\n",
            " \n",
            "p\n",
            "o\n",
            "l\n",
            "i\n",
            "s\n",
            "h\n",
            "e\n",
            "d\n",
            " \n",
            "m\n",
            "a\n",
            "n\n",
            " \n",
            "o\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            ".\n",
            " \n",
            " \n",
            "P\n",
            "e\n",
            "o\n",
            "p\n",
            "l\n",
            "e\n",
            " \n",
            "s\n",
            "a\n",
            "i\n",
            "d\n",
            "\n",
            "\n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "e\n",
            "s\n",
            "e\n",
            "m\n",
            "b\n",
            "l\n",
            "e\n",
            "d\n",
            " \n",
            "B\n",
            "y\n",
            "r\n",
            "o\n",
            "n\n",
            "-\n",
            "-\n",
            "a\n",
            "t\n",
            " \n",
            "l\n",
            "e\n",
            "a\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "h\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIpsGrV0-2fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_len+1,drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vquq-ABf-2fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_target(seq):\n",
        "    input_text = seq[:-1]\n",
        "    target_text = seq[1:]\n",
        "    return input_text,target_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A-AT8U5-2fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = sequences.map(seq_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COR6zQPq-2fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75f7e44a-a561-4565-f154-52282c5233d7"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((250,), (250,)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vJMEqfi-2ft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "53f077ad-b7f7-43ae-fd76-13d67657b33c"
      },
      "source": [
        "for input_txt, target_txt in  dataset.take(1):\n",
        "    print(input_txt.numpy())\n",
        "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_txt.numpy())\n",
        "    print(''.join(ind_to_char[target_txt.numpy()]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[27 59 52 67 71 56 69  1 33  0  0 33 38  1 47 32 33 27 32  1 40 32 33 36\n",
            " 29 25 43  1 30 39 31 31  1 25 38 28  1 40 25 43 43 29 40 25 42 44 39 45\n",
            " 44  1 25 27 27 29 40 44  1 29 25 27 32  1 39 44 32 29 42  9  0 44 32 29\n",
            "  1 39 38 29  1 25 43  1 37 25 43 44 29 42  9  1 44 32 29  1 39 44 32 29\n",
            " 42  1 25 43  1 37 25 38  0  0  0 37 69 11  1 40 59 60 63 56 52 70  1 30\n",
            " 66 58 58  1 63 60 73 56 55  9  1 60 65  1 13 20 19 14  9  1 52 71  1 38\n",
            " 66 11  1 19  9  1 43 52 73 60 63 63 56  1 42 66 74  9  1 26 72 69 63 60\n",
            " 65 58 71 66 65  0 31 52 69 55 56 65 70  9  1 71 59 56  1 59 66 72 70 56\n",
            "  1 60 65  1 74 59 60 54 59  1 43 59 56 69 60 55 52 65  1 55 60 56 55  1\n",
            " 60 65  1 13 20 13 16 11  1  1 32 56  1 74 52 70  1 66 65 56  1 66 57  1\n",
            " 71 59 56  0 64 66 70 71  1 65]\n",
            "Chapter I\n",
            "\n",
            "IN WHICH PHILEAS FOGG AND PASSEPARTOUT ACCEPT EACH OTHER,\n",
            "THE ONE AS MASTER, THE OTHER AS MAN\n",
            "\n",
            "\n",
            "Mr. Phileas Fogg lived, in 1872, at No. 7, Saville Row, Burlington\n",
            "Gardens, the house in which Sheridan died in 1814.  He was one of the\n",
            "most n\n",
            "\n",
            "\n",
            "[59 52 67 71 56 69  1 33  0  0 33 38  1 47 32 33 27 32  1 40 32 33 36 29\n",
            " 25 43  1 30 39 31 31  1 25 38 28  1 40 25 43 43 29 40 25 42 44 39 45 44\n",
            "  1 25 27 27 29 40 44  1 29 25 27 32  1 39 44 32 29 42  9  0 44 32 29  1\n",
            " 39 38 29  1 25 43  1 37 25 43 44 29 42  9  1 44 32 29  1 39 44 32 29 42\n",
            "  1 25 43  1 37 25 38  0  0  0 37 69 11  1 40 59 60 63 56 52 70  1 30 66\n",
            " 58 58  1 63 60 73 56 55  9  1 60 65  1 13 20 19 14  9  1 52 71  1 38 66\n",
            " 11  1 19  9  1 43 52 73 60 63 63 56  1 42 66 74  9  1 26 72 69 63 60 65\n",
            " 58 71 66 65  0 31 52 69 55 56 65 70  9  1 71 59 56  1 59 66 72 70 56  1\n",
            " 60 65  1 74 59 60 54 59  1 43 59 56 69 60 55 52 65  1 55 60 56 55  1 60\n",
            " 65  1 13 20 13 16 11  1  1 32 56  1 74 52 70  1 66 65 56  1 66 57  1 71\n",
            " 59 56  0 64 66 70 71  1 65 66]\n",
            "hapter I\n",
            "\n",
            "IN WHICH PHILEAS FOGG AND PASSEPARTOUT ACCEPT EACH OTHER,\n",
            "THE ONE AS MASTER, THE OTHER AS MAN\n",
            "\n",
            "\n",
            "Mr. Phileas Fogg lived, in 1872, at No. 7, Saville Row, Burlington\n",
            "Gardens, the house in which Sheridan died in 1814.  He was one of the\n",
            "most no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPOb1-d3-2fw",
        "colab_type": "text"
      },
      "source": [
        "# training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2KVk4sd-2fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "buffer_size = 10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNpHAhrK-2fz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70e691ed-6302-48c2-f980-44d8a13cc6a0"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 250), (128, 250)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij-HJYbJ-2f3",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UH-qvzV-2f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "embed_dim = 256\n",
        "rnn_neurons = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBX4W7f3-2f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding,Dropout,GRU\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "julyhRLt-2f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_cat(y_true,y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true,y_pred, from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMSjVwJI-2gB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b8d1c878-7f5d-4f20-d1a6-5ef5defdce73"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
        "model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "model.add(Dense(vocab_size))\n",
        "model.compile(optimizer='adam',loss=sparse_cat)\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 256)          19968     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (128, None, 1024)         3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 78)           79950     \n",
            "=================================================================\n",
            "Total params: 4,038,222\n",
            "Trainable params: 4,038,222\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mcLCLv--2gF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e47e338-8481-471d-fb53-07689697f563"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  # Predict off some random batch\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "  # Display the dimensions of the predictions\n",
        "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 250, 78)  <=== (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65m3-CHU-2gI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a707266-afc2-4ffc-8d02-e061c147ec30"
      },
      "source": [
        "example_batch_predictions"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 250, 78), dtype=float32, numpy=\n",
              "array([[[-1.33452639e-02,  7.75482878e-03, -3.92885972e-03, ...,\n",
              "          6.38161087e-04,  9.62015940e-04, -8.96746665e-03],\n",
              "        [-5.09776454e-03,  7.86013203e-04,  9.43000778e-04, ...,\n",
              "          9.26185865e-04, -1.67493857e-02, -1.33211948e-02],\n",
              "        [-6.34637335e-03,  6.57085655e-03, -4.64505330e-03, ...,\n",
              "          1.67192463e-02, -5.60679333e-03,  2.30835611e-03],\n",
              "        ...,\n",
              "        [ 7.54932780e-03,  3.76665965e-03, -1.00452062e-02, ...,\n",
              "         -1.38662066e-02, -5.14511624e-03,  5.95049839e-03],\n",
              "        [ 1.31298732e-02, -1.24759218e-02, -8.53822194e-03, ...,\n",
              "         -1.20699853e-02,  1.29118431e-02,  3.68272595e-05],\n",
              "        [ 1.94363613e-02, -2.26227697e-02, -6.65093819e-03, ...,\n",
              "         -8.98689311e-03,  1.85874794e-02, -2.94574420e-03]],\n",
              "\n",
              "       [[-2.20786803e-03,  4.79261577e-03,  3.40996915e-03, ...,\n",
              "         -1.39263757e-02, -1.81582868e-02, -2.19238224e-03],\n",
              "        [-5.22776041e-03, -6.47777598e-03,  4.57732985e-03, ...,\n",
              "         -6.19689468e-04, -1.67645738e-02,  2.11253855e-03],\n",
              "        [-7.24562816e-03, -7.73217762e-04,  6.18196465e-03, ...,\n",
              "         -1.62767041e-02, -2.56021284e-02, -3.06183286e-03],\n",
              "        ...,\n",
              "        [-1.68243013e-02, -8.86314269e-03, -7.64887454e-03, ...,\n",
              "         -9.15715354e-04,  5.78876399e-03,  4.98739537e-03],\n",
              "        [-7.20539596e-03, -1.46332495e-02,  3.18657141e-03, ...,\n",
              "         -8.53211619e-04,  2.60716230e-02,  8.13357159e-03],\n",
              "        [-4.72261664e-03, -4.57765441e-03, -3.51396482e-03, ...,\n",
              "          1.49470437e-02,  1.76875442e-02,  1.59232654e-02]],\n",
              "\n",
              "       [[-5.80691686e-03,  8.10332876e-03, -2.74909870e-03, ...,\n",
              "          2.43978994e-03,  1.85874291e-04,  4.67263814e-03],\n",
              "        [-8.93623289e-03,  2.38260813e-03,  6.25303481e-03, ...,\n",
              "         -4.09317482e-03,  4.42495011e-03, -6.46295445e-03],\n",
              "        [-9.90785379e-03, -6.99862605e-04,  9.61116329e-03, ...,\n",
              "         -8.09073634e-03,  5.12861414e-03, -9.73978825e-03],\n",
              "        ...,\n",
              "        [-1.11208595e-02, -9.19044111e-03,  4.28028405e-03, ...,\n",
              "         -2.58495100e-04, -1.53819602e-02,  4.60119732e-03],\n",
              "        [ 3.47493310e-03, -2.25668261e-03,  7.83340074e-04, ...,\n",
              "          8.98014382e-03, -1.70747600e-02, -8.26757587e-03],\n",
              "        [ 4.38980758e-04, -1.27921347e-02,  6.92052580e-03, ...,\n",
              "          3.63453710e-03,  1.29721053e-02,  9.41178529e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 3.53550259e-03,  2.28088349e-03,  1.22312838e-02, ...,\n",
              "         -1.24828406e-02, -1.24970404e-02,  7.84115680e-03],\n",
              "        [-1.97529746e-03,  5.57846949e-03,  1.26964203e-03, ...,\n",
              "          9.36564989e-03, -1.18294696e-03,  1.35588469e-02],\n",
              "        [ 3.26916459e-03,  1.28049143e-02,  1.47443917e-02, ...,\n",
              "          1.06870979e-02,  8.58353358e-03,  1.83082223e-02],\n",
              "        ...,\n",
              "        [-1.10472124e-02, -4.11264785e-03,  4.58874879e-03, ...,\n",
              "         -3.85508453e-03, -9.87260044e-03, -6.77038776e-03],\n",
              "        [-2.20123865e-03, -4.68435604e-03,  3.36447009e-03, ...,\n",
              "         -2.19112122e-03, -2.02253386e-02, -1.37401614e-02],\n",
              "        [ 3.72842024e-03,  1.13740331e-02,  1.11954212e-02, ...,\n",
              "          5.49057964e-03, -7.08926120e-04,  2.06763856e-03]],\n",
              "\n",
              "       [[-1.00407493e-03, -4.90467995e-04,  2.82692071e-03, ...,\n",
              "          2.11035041e-03, -6.14117132e-04, -1.15016736e-02],\n",
              "        [-1.53853875e-02, -3.86522803e-03, -2.73570325e-03, ...,\n",
              "         -2.07632687e-03, -5.74752130e-03, -3.17241065e-05],\n",
              "        [-2.05514319e-02,  6.22898433e-03, -6.53476175e-03, ...,\n",
              "          6.39062142e-04, -1.95161602e-03, -9.73795261e-03],\n",
              "        ...,\n",
              "        [ 4.89801448e-03, -3.65976011e-03,  3.41238192e-04, ...,\n",
              "         -4.28943662e-04, -4.33900952e-03,  1.05152447e-02],\n",
              "        [-3.36156460e-03, -1.44086685e-03, -1.55169126e-02, ...,\n",
              "         -1.74009707e-04,  9.22852545e-04,  1.24849076e-03],\n",
              "        [-6.53438363e-03,  1.83512177e-03, -1.16022332e-02, ...,\n",
              "          1.50735164e-02,  6.56969007e-03,  1.22208297e-02]],\n",
              "\n",
              "       [[-1.33452639e-02,  7.75482878e-03, -3.92885972e-03, ...,\n",
              "          6.38161087e-04,  9.62015940e-04, -8.96746665e-03],\n",
              "        [-8.69015232e-03, -5.29364590e-03,  5.59885707e-03, ...,\n",
              "          7.24304002e-04,  1.86701342e-02,  3.66403745e-03],\n",
              "        [-1.99410841e-02, -8.18909798e-03, -7.43114855e-04, ...,\n",
              "         -3.77520337e-03,  2.14302214e-03,  1.05348909e-02],\n",
              "        ...,\n",
              "        [-2.39747763e-02, -5.53610642e-03, -1.42105028e-03, ...,\n",
              "         -5.54461125e-03, -1.85516644e-02, -2.32819002e-04],\n",
              "        [-2.76840087e-02, -1.00030852e-02, -5.15023293e-03, ...,\n",
              "         -6.70075696e-03, -1.39826508e-02,  6.51588012e-03],\n",
              "        [-3.59591423e-03, -2.18682587e-02, -6.05608057e-03, ...,\n",
              "         -5.54406969e-03,  6.63550571e-03, -3.94354691e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTDRguBT-2gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWCRFL1y-2gQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "635668a9-b684-4bf6-f173-5cf6d9a15ca4"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(250, 1), dtype=int64, numpy=\n",
              "array([[56],\n",
              "       [62],\n",
              "       [65],\n",
              "       [29],\n",
              "       [17],\n",
              "       [ 8],\n",
              "       [23],\n",
              "       [71],\n",
              "       [ 5],\n",
              "       [63],\n",
              "       [26],\n",
              "       [65],\n",
              "       [ 6],\n",
              "       [13],\n",
              "       [64],\n",
              "       [38],\n",
              "       [49],\n",
              "       [44],\n",
              "       [12],\n",
              "       [33],\n",
              "       [35],\n",
              "       [40],\n",
              "       [16],\n",
              "       [59],\n",
              "       [24],\n",
              "       [68],\n",
              "       [44],\n",
              "       [38],\n",
              "       [21],\n",
              "       [ 5],\n",
              "       [35],\n",
              "       [13],\n",
              "       [36],\n",
              "       [43],\n",
              "       [49],\n",
              "       [31],\n",
              "       [ 8],\n",
              "       [50],\n",
              "       [ 1],\n",
              "       [53],\n",
              "       [71],\n",
              "       [57],\n",
              "       [15],\n",
              "       [10],\n",
              "       [33],\n",
              "       [18],\n",
              "       [52],\n",
              "       [22],\n",
              "       [68],\n",
              "       [31],\n",
              "       [25],\n",
              "       [11],\n",
              "       [37],\n",
              "       [ 7],\n",
              "       [18],\n",
              "       [ 8],\n",
              "       [47],\n",
              "       [65],\n",
              "       [ 4],\n",
              "       [65],\n",
              "       [18],\n",
              "       [52],\n",
              "       [66],\n",
              "       [73],\n",
              "       [42],\n",
              "       [40],\n",
              "       [30],\n",
              "       [48],\n",
              "       [15],\n",
              "       [36],\n",
              "       [63],\n",
              "       [14],\n",
              "       [ 4],\n",
              "       [25],\n",
              "       [46],\n",
              "       [45],\n",
              "       [44],\n",
              "       [77],\n",
              "       [ 0],\n",
              "       [72],\n",
              "       [38],\n",
              "       [21],\n",
              "       [24],\n",
              "       [46],\n",
              "       [24],\n",
              "       [22],\n",
              "       [16],\n",
              "       [33],\n",
              "       [ 9],\n",
              "       [61],\n",
              "       [57],\n",
              "       [ 5],\n",
              "       [61],\n",
              "       [ 0],\n",
              "       [33],\n",
              "       [41],\n",
              "       [53],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [ 2],\n",
              "       [35],\n",
              "       [73],\n",
              "       [14],\n",
              "       [40],\n",
              "       [ 3],\n",
              "       [38],\n",
              "       [41],\n",
              "       [48],\n",
              "       [14],\n",
              "       [62],\n",
              "       [75],\n",
              "       [12],\n",
              "       [20],\n",
              "       [57],\n",
              "       [60],\n",
              "       [24],\n",
              "       [20],\n",
              "       [24],\n",
              "       [14],\n",
              "       [14],\n",
              "       [11],\n",
              "       [70],\n",
              "       [28],\n",
              "       [62],\n",
              "       [46],\n",
              "       [ 0],\n",
              "       [40],\n",
              "       [66],\n",
              "       [64],\n",
              "       [18],\n",
              "       [72],\n",
              "       [73],\n",
              "       [73],\n",
              "       [56],\n",
              "       [65],\n",
              "       [ 6],\n",
              "       [21],\n",
              "       [42],\n",
              "       [21],\n",
              "       [19],\n",
              "       [23],\n",
              "       [24],\n",
              "       [ 5],\n",
              "       [19],\n",
              "       [ 4],\n",
              "       [14],\n",
              "       [16],\n",
              "       [56],\n",
              "       [28],\n",
              "       [36],\n",
              "       [68],\n",
              "       [71],\n",
              "       [18],\n",
              "       [29],\n",
              "       [31],\n",
              "       [42],\n",
              "       [65],\n",
              "       [67],\n",
              "       [46],\n",
              "       [ 7],\n",
              "       [18],\n",
              "       [52],\n",
              "       [26],\n",
              "       [37],\n",
              "       [ 3],\n",
              "       [ 5],\n",
              "       [28],\n",
              "       [39],\n",
              "       [73],\n",
              "       [ 0],\n",
              "       [ 0],\n",
              "       [60],\n",
              "       [23],\n",
              "       [ 5],\n",
              "       [34],\n",
              "       [ 9],\n",
              "       [56],\n",
              "       [32],\n",
              "       [71],\n",
              "       [56],\n",
              "       [30],\n",
              "       [21],\n",
              "       [26],\n",
              "       [25],\n",
              "       [23],\n",
              "       [ 4],\n",
              "       [47],\n",
              "       [55],\n",
              "       [47],\n",
              "       [38],\n",
              "       [17],\n",
              "       [ 0],\n",
              "       [54],\n",
              "       [55],\n",
              "       [21],\n",
              "       [61],\n",
              "       [56],\n",
              "       [52],\n",
              "       [22],\n",
              "       [ 7],\n",
              "       [71],\n",
              "       [ 3],\n",
              "       [49],\n",
              "       [73],\n",
              "       [56],\n",
              "       [27],\n",
              "       [60],\n",
              "       [ 1],\n",
              "       [ 8],\n",
              "       [17],\n",
              "       [35],\n",
              "       [22],\n",
              "       [22],\n",
              "       [18],\n",
              "       [23],\n",
              "       [12],\n",
              "       [31],\n",
              "       [72],\n",
              "       [56],\n",
              "       [17],\n",
              "       [37],\n",
              "       [53],\n",
              "       [61],\n",
              "       [42],\n",
              "       [21],\n",
              "       [10],\n",
              "       [48],\n",
              "       [58],\n",
              "       [71],\n",
              "       [57],\n",
              "       [14],\n",
              "       [ 1],\n",
              "       [ 0],\n",
              "       [64],\n",
              "       [72],\n",
              "       [22],\n",
              "       [67],\n",
              "       [38],\n",
              "       [31],\n",
              "       [53],\n",
              "       [54],\n",
              "       [55],\n",
              "       [12],\n",
              "       [ 3],\n",
              "       [75],\n",
              "       [19],\n",
              "       [33],\n",
              "       [15],\n",
              "       [38],\n",
              "       [ 8]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQgQmrir-2gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1sRTjvn-2gW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1d8198ca-d6ff-4082-a202-cdaf787e73e4"
      },
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(ind_to_char[sampled_indices ]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Given the input seq: \n",
            "\n",
            "travelling in the\n",
            "open air, Mr. Fogg proposed to leave her with Passepartout at Fort\n",
            "Kearney, the servant taking upon himself to escort her to Europe by a\n",
            "better route and under more favourable conditions.  But Aouda refused\n",
            "to separate from Mr. Fogg\n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "eknE5+;t'lBn(1mNYT0IKP4h?qTN9'K1LSYG+Z btf3-I6a:qGA.M)6+Wn&n6aovRPFX3Ll2&AVUTz\n",
            "uN9?V?:4I,jf'j\n",
            "IQb\n",
            "\n",
            "!Kv2P\"NQX2kx08fi?8?22.sDkV\n",
            "Pom6uvven(9R97;?'7&24eDLqt6EGRnpV)6aBM\"'DOv\n",
            "\n",
            "i;'J,eHteF9BA;&WdWN5\n",
            "cd9jea:)t\"YveCi +5K::6;0Gue5MbjR9-Xgtf2 \n",
            "mu:pNGbcd0\"x7I3N+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDmyMYW1BC0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51d26cf2-ec76-4527-9b3f-5cd39719a00d"
      },
      "source": [
        "model.fit(dataset,epochs=60)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "11/11 [==============================] - 2s 213ms/step - loss: 4.3544\n",
            "Epoch 2/60\n",
            "11/11 [==============================] - 2s 215ms/step - loss: 3.4614\n",
            "Epoch 3/60\n",
            "11/11 [==============================] - 2s 216ms/step - loss: 3.0239\n",
            "Epoch 4/60\n",
            "11/11 [==============================] - 2s 218ms/step - loss: 2.8426\n",
            "Epoch 5/60\n",
            "11/11 [==============================] - 2s 218ms/step - loss: 2.6788\n",
            "Epoch 6/60\n",
            "11/11 [==============================] - 2s 218ms/step - loss: 2.5609\n",
            "Epoch 7/60\n",
            "11/11 [==============================] - 2s 220ms/step - loss: 2.4719\n",
            "Epoch 8/60\n",
            "11/11 [==============================] - 2s 220ms/step - loss: 2.4118\n",
            "Epoch 9/60\n",
            "11/11 [==============================] - 2s 223ms/step - loss: 2.3639\n",
            "Epoch 10/60\n",
            "11/11 [==============================] - 2s 222ms/step - loss: 2.3183\n",
            "Epoch 11/60\n",
            "11/11 [==============================] - 2s 224ms/step - loss: 2.2787\n",
            "Epoch 12/60\n",
            "11/11 [==============================] - 2s 225ms/step - loss: 2.2380\n",
            "Epoch 13/60\n",
            "11/11 [==============================] - 2s 225ms/step - loss: 2.1964\n",
            "Epoch 14/60\n",
            "11/11 [==============================] - 2s 227ms/step - loss: 2.1566\n",
            "Epoch 15/60\n",
            "11/11 [==============================] - 3s 228ms/step - loss: 2.1157\n",
            "Epoch 16/60\n",
            "11/11 [==============================] - 3s 228ms/step - loss: 2.0752\n",
            "Epoch 17/60\n",
            "11/11 [==============================] - 3s 229ms/step - loss: 2.0324\n",
            "Epoch 18/60\n",
            "11/11 [==============================] - 3s 230ms/step - loss: 1.9900\n",
            "Epoch 19/60\n",
            "11/11 [==============================] - 3s 231ms/step - loss: 1.9490\n",
            "Epoch 20/60\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 1.9070\n",
            "Epoch 21/60\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 1.8687\n",
            "Epoch 22/60\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 1.8291\n",
            "Epoch 23/60\n",
            "11/11 [==============================] - 3s 236ms/step - loss: 1.7913\n",
            "Epoch 24/60\n",
            "11/11 [==============================] - 3s 237ms/step - loss: 1.7537\n",
            "Epoch 25/60\n",
            "11/11 [==============================] - 3s 237ms/step - loss: 1.7197\n",
            "Epoch 26/60\n",
            "11/11 [==============================] - 3s 240ms/step - loss: 1.6845\n",
            "Epoch 27/60\n",
            "11/11 [==============================] - 3s 243ms/step - loss: 1.6500\n",
            "Epoch 28/60\n",
            "11/11 [==============================] - 3s 241ms/step - loss: 1.6184\n",
            "Epoch 29/60\n",
            "11/11 [==============================] - 3s 240ms/step - loss: 1.5877\n",
            "Epoch 30/60\n",
            "11/11 [==============================] - 3s 240ms/step - loss: 1.5555\n",
            "Epoch 31/60\n",
            "11/11 [==============================] - 3s 239ms/step - loss: 1.5269\n",
            "Epoch 32/60\n",
            "11/11 [==============================] - 3s 238ms/step - loss: 1.4998\n",
            "Epoch 33/60\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 1.4730\n",
            "Epoch 34/60\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 1.4457\n",
            "Epoch 35/60\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 1.4223\n",
            "Epoch 36/60\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 1.3995\n",
            "Epoch 37/60\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 1.3777\n",
            "Epoch 38/60\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 1.3526\n",
            "Epoch 39/60\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 1.3323\n",
            "Epoch 40/60\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 1.3102\n",
            "Epoch 41/60\n",
            "11/11 [==============================] - 3s 231ms/step - loss: 1.2923\n",
            "Epoch 42/60\n",
            "11/11 [==============================] - 3s 231ms/step - loss: 1.2712\n",
            "Epoch 43/60\n",
            "11/11 [==============================] - 3s 231ms/step - loss: 1.2521\n",
            "Epoch 44/60\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 1.2347\n",
            "Epoch 45/60\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 1.2163\n",
            "Epoch 46/60\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 1.1986\n",
            "Epoch 47/60\n",
            "11/11 [==============================] - 3s 231ms/step - loss: 1.1797\n",
            "Epoch 48/60\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 1.1635\n",
            "Epoch 49/60\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 1.1451\n",
            "Epoch 50/60\n",
            "11/11 [==============================] - 3s 234ms/step - loss: 1.1271\n",
            "Epoch 51/60\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 1.1089\n",
            "Epoch 52/60\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 1.0928\n",
            "Epoch 53/60\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 1.0753\n",
            "Epoch 54/60\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 1.0597\n",
            "Epoch 55/60\n",
            "11/11 [==============================] - 3s 237ms/step - loss: 1.0421\n",
            "Epoch 56/60\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 1.0246\n",
            "Epoch 57/60\n",
            "11/11 [==============================] - 3s 234ms/step - loss: 1.0090\n",
            "Epoch 58/60\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 0.9935\n",
            "Epoch 59/60\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 0.9727\n",
            "Epoch 60/60\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 0.9548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1862936da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4h_nC-sBb2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/jv-model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrUPAIBO-2gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKoy0VIX-2gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[1,None]))\n",
        "model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "model.add(Dense(vocab_size))\n",
        "model.compile(optimizer='adam',loss=sparse_cat)\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/jv-model.h5')\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7yXIbTH-2go",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e4117676-9029-4866-cc9d-ad8da0e80db2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (1, None, 256)            19968     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 78)             79950     \n",
            "=================================================================\n",
            "Total params: 4,038,222\n",
            "Trainable params: 4,038,222\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BU1EMiB-2gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        "  '''\n",
        "  model: Trained Model to Generate Text\n",
        "  start_seed: Intial Seed text in string form\n",
        "  gen_size: Number of characters to generate\n",
        "\n",
        "  Basic idea behind this function is to take in some seed text, format it so\n",
        "  that it is in the correct shape for our network, then loop the sequence as\n",
        "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
        "  time series problems.\n",
        "  '''\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = gen_size\n",
        "\n",
        "  # Vecotrizing starting seed text\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "\n",
        "  # Expand to match batch format shape\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty list to hold resulting generated text\n",
        "  text_generated = []\n",
        "\n",
        "  # Temperature effects randomness in our resulting text\n",
        "  # The term is derived from entropy/thermodynamics.\n",
        "  # The temperature is used to effect probability of next characters.\n",
        "  # Higher probability == lesss surprising/ more expected\n",
        "  # Lower temperature == more surprising / less expected\n",
        " \n",
        "  temperature = temp\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "\n",
        "      # Generate Predictions\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      # Remove the batch shape dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # Use a cateogircal disitribution to select the next character\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # Pass the predicted charracter for the next input\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      # Transform back to character letter\n",
        "      text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dHeY5KA-2gv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b8ecaf25-205e-431d-ab38-c2cbba7e7eea"
      },
      "source": [
        "print(generate_text(model,\"Aouda\",gen_size=500)) #Aouda and  Passepartout are characters from the novel"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aouda. Yow, then, is for from the selvenent of arrest my complements.  As for Passepartout, which he catevers scatce he see off, and\n",
            "quemed by\n",
            "a probres by watco followed at the train what owed to him a lear of advirally upon could be\n",
            "soveres to\n",
            "men; but there would come in\n",
            "the since he was by bricks and whirtered like a small.  Aouda had, gonds of gallaged, whither are prudent from impassious.\n",
            "\n",
            "If the detective e.s not admitiously mutterly graved to\n",
            "get-followed upon his faces out of Indians,\n",
            "meridi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5hvS6KI-2g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}